Dati:
    - TransactionID (string, unique ma duplicato se ci son più prodotti nella stessa transazione)
    - ProductID (string, unique ma duplicato se compare più di una volta)
    - Description of the product
    - Quantity (integer, negativo se restituito)
    - InvoiceDate (string, "YYYY-MM-DD hh:mm")
    - UnitPrice (real)
    - CustomerID (integer, unique ma duplicato se ha comprato più di due prodotti)
    - Country (string)

Compiti:
    CLI:
        - K (int) numero di partizioni RDD
        - H (int) filtro su top H prodotti popolari per ultimo task
        - S (string) filtro sul paese, può essere "all" per accettare tutto
        - path del file
    Task:
        1 (productCustomer):
            Select prodictID, customerID where quantity > 0 and country = *S*
            !! non si può far finire tutti i prodotti dentro un singolo reduce (invece si può assumere che (P,C) siano pochi)
        2 (productPopularity1) partendo da productCustomer, usando _mapPartitions/mapPartitionsToPair_:
            select productID, distinct(count(customerId)) group by productID
            !! si può assumere di far finire tutti i record di un prodotto su un reduce
        3 (productPopularity2) rifare (1) e (2) usando _map/mapToPair_ e _reduceByKey_
        4 SE H>0 
            salva in una lista e stampa i primi H prodotti estraendoli da productPopularity1 
            (quindi non si può assumere di scaricare tutto e filtrare, bisogna fare su spark il maxheap)
          SE H==0
            si prende tutte le coppie sia da productPopularity1 che da productPopularity2,
            li salva in una lista e stampa tutto, in ordine lessicografico
        